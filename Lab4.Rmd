---
title: "GEOG 4023/5023: Advanced Quant Methods for Geographic Data"
subtitle: "Lab 6: Logistic Regression"
author: Jason Lee
output: 
  html_document:
    css: "lab.css"
---

```{r setup, include=FALSE}
# Setup the environment
library(knitr)
knitr::opts_chunk$set(fig.align='center',fig.width=10, fig.height=6, fig.path='Figs/',  warning=FALSE, echo=TRUE, eval=TRUE, message=FALSE)

r = getOption("repos")
r["CRAN"] = "http://cran.us.r-project.org"
options(repos = r)
```

<div class="instructions">

Please complete the following questions and submit the finished Rmd and HTML file onto Canvas. 

Don't forget to change name field in the beginning to your **first and last name**. 

</div>

## Objectives

  - Learn how to make maps with `ggplot`
  - Understand how to use logistic regression in practices
  - Understand the performance metrics of logistic regression
  - Understand the variable selections in logistic regression
  - Understand the diagnostics and assumptions of logistic regression

## Introduction 

In this lab, we will review basics of logistic regression and apply
it to a problem in spatial settings. We will try to map 
the landslide susceptibility with the help of auxiliary geographic
and geomorphologic variables, e.g., elevation and slope. It is based on a
study of landslide locations in Southern Ecuador: [Muenchow, Brenning, and Richter (2012)](./Data/Muenchow, Brenning & Richter.pdf).

## Data

The data containing the landslide points, with the corresponding terrain
attributes (`landslides.rds` in the enclosed `Data` folder), and
geographic boundary of the study area (`boundary.shp`), along with the
terrain attribute raster stack from which the values were extracted
(`terrain.rds`). The terrain attributes includes the following:
 
  - `slope`: slope angle (unit: degree).
  - `cplan`: plan curvature (rad $m^{−1}$) expressing the convergence or
    divergence of a slope and thus water flow. See [this
    link](https://www.esri.com/arcgis-blog/products/product/imagery/understanding-curvature-rasters/) you are interested in knowing more about plan curvature
  - `cprof`: profile curvature (rad $m^{−1}$) as a measure of flow
    acceleration, also known as downslope change in slope angle. See [this
    link](https://www.esri.com/arcgis-blog/products/product/imagery/understanding-curvature-rasters/) you are interested in knowing more about plan curvature
  -  `elev`: elevation (m) as the representation of different altitudinal zones of vegetation and precipitation in the study area.
  -  `log10_carea`: the decadic logarithm of the catchment area ($log_{10}m^2$) representing the amount of water flowing towards a location.


## Setup

We will use the package `ggplot2` for the mapping (feel free to use other
packages too, such as `ggmap` or `tmap`; see the pages 63-76 in the
[enclosed slides](./Data/Graphics&Mapping.pdf)). We will use `sf` for the
reading and writing of files. Similar as the multiple
regression lab of last week, we will primarily rely on `glm()` for the
logistic regression this lab, which doesn't need extra package. Let's first load the library and related GIS library. If you have not installed it on your computer, please install by command  `install.packages()` or the bottom right menu in `RStudio`. Feel free to use other libraries too.

```{r, echo=T, eval=T}
library(ggplot2)
library(sf)
library(maptools)
library(maps)
library(raster)
library(ggsn)
```

## Mapping

Let's first load the data and take a look at what the data look like. 

```{r}

# load the boundary of study area
boundary=st_read("Data/boundary.shp")
# check the data type
class(boundary)

# load the landsldies points
landslides=readRDS("Data/landslides.rds")
# check the data types
class(landslides)
# see the information of the data frame
str(landslides)
# load the terrain attributes
terrain <- readRDS("Data/terrain.rds")
# check the data types
class(terrain)
 # check the dimension of terrain, we can see that there are 5 layers of rasters
dim(terrain)
 # check the names of each layer
names(terrain)
```

As we can see that the variable `landslides` is a data frame with x and y
coordinates and the associated terrain attribute measurements in the
location, and `terrain` is a `rasterstack` with 5 raster layers of different
terrain attributes that the `landslides` extracted the attributes from.
The `landslides` has a column `lslpts`, a logical variable indicating the
presences or absence of landslides at each location.

## Mapping 

Now let's use `ggplot2` to map the data out and see how they look like.
`ggplot2`  works well with the data type of `data.frame`. Here the
`boundary` is a `sf data.frame` that can be mapped with `geom_sf()` and
`landslides` is a regular `data.frame` that can be visualized with
`geom_point()`. See the following:

```{r}
ggplot() +
    geom_sf(data=boundary, aes(color='green')) +
    geom_point(data= landslides, aes(x =x, y=y, color=lslpts)) 
```

The `terrain` is in `rasterstack` data type. To map it with `ggplot`, we need to
convert it to a `data.frame`. The `elev` layer can be mapped with the
following codes:

```{r}

terrain.df=as.data.frame(terrain, xy=T, na.rm=T)

ggplot() +
    geom_raster(data=terrain.df, aes(x=x, y=y, fill=elev))

```

We can change the color scale to make it look better. The package
`RColorBrewer` provides set of ready-to-use color scheme that can be displayed:

```{r}
library(RColorBrewer)
display.brewer.all()
```

The first set of color palettes are *sequential* palettes and are suitable
for a variable that has ordinal meaning: elevation, temperature,
precipitation, etc. The second set of palettes are *qualitative* palettes
and suitable for qualitative or categorical data. Finally, the third set of
palettes are *diverging* palettes and can be suitable for variables that
take both negative and positive values like changes in groundwater level. 

We can change the color scale of the previous rater map to `OrRd` palette:

```{r}
ggplot() +
    geom_raster(data=terrain.df, aes(x=x, y=y, fill=elev)) +
      scale_fill_distiller(palette = "OrRd")
```

<div class="question">

**Q1:** Please make a map by overlaying the landslides points and the boundary of study area on the `slope` layer of the `terrain` rasterstack .
Note that not every point has presences of landslides (as indicated by
`lslpts`), please differentiate presences and absences with different colors or symbols in the map. Please also adjust the color ramp to fit your taste of
color scheme. (10 pts)

**Your answer:**

```{r}
# please type your codes here:
terrain_df = as.data.frame(terrain, xy = T, na.rm = T)

ggplot() +
  geom_raster(data = terrain_df, aes(x = x, y = y, fill = slope)) +
  scale_fill_gradientn(colors = terrain.colors(10)) +
  geom_point(data = landslides, aes(x = x, y = y, color = lslpts), size = 1.5) +
  geom_sf(data = boundary, aes(color = 'green')) +
  scale_color_manual(values = c("black", "red", "blue"))
```

</div>


## Logistic regression

We are interested in what terrain variables will contribute to the
presences of the landslides (`lslpts`) and how. Many approaches are
available for this purpose from different perspectives. In regression
settings, logistic regression is perhaps one of the most commonly used
method for binary response variable. We talked about it in the class a
couple of weeks ago (see page 39 of the [enclosed slides](./Data/slides3-exported.pdf)). Logistic regression belongs to the family of generalized linear models
(GLM) that primarily deal with non-Gaussian response variables. Another
commonly used GLM is Poisson regression for number of events (e.g., trees,
crimes). 

Let's start with a full model: 

```{r}
fitFull = glm(lslpts ~ slope + cplan + cprof + elev + log10_carea,
          family = binomial(),
          data = landslides)
summary(fitFull)
```


<div class="question">

**Q2:** As you can see that the full model has several insignificant
variables. Please try to improve the full model (call it `fitSmall`) with a
set of variables that are statistically significant and you think most
relevant to the presences of landslides (`lslpts`). Please also show why
the model (`fitSmall`) is better than the full model (`fitFull`)?
*Hint* You can manually select the variables (with trial and error) or use the `step()`. (20 pts)

**Your answer:**

```{r}
# please type your codes here:
fitSmall <- glm(lslpts ~ slope + elev + log10_carea, 
                family = binomial(),
                data = landslides)
summary(fitSmall)

AIC(fitFull)
AIC(fitSmall)
```

</div>

Cross-validation is a commonly used approach to evaluate the estimation
performance of a model. We talk about it in the lecture (please see page 7
of the [enclosed slides](./Data/slides3-exported.pdf)). Simply put, cross-validation separates the measurements into groups, one of the groups selected as a validation group and the rest as training groups to train the model. The trained model is then used to make estimations for validation group. By looking at the discrepancies between the original measurements and the estimation of the validation group, we can have a measure of the estimation error. Two cross-validation types are often used: leave-one-out cross-validation (LOOCV) or k-fold cross-validation.

Cross-validation for GLM can be conducted using `cv.glm()` provided in the
package `boot` (install by `install.packages('boot')`). For the full model,
e.g., the estimation error can be obtained by: 

```{r}
library(boot)
# leave one-out cross valiation
cvFull <- cv.glm(data=landslides, fitFull)
# estimation error
cvFull$delta[1]
# k-fold, k=10
cvFull <- cv.glm(data=landslides, fitFull, K=10)
cvFull$delta[1]
```

<div class="question">
**Q3:** Please conduct the cross-validation for `fitSmall` based on the above
codes (using both methods) and compare the performances of the two model (`fitFull` and
`fitSmall`) (20 pts)

**Your answer:**


```{r}
# please type your codes here
# Conducting leave-one-out cross validation for fitSmall
cvSmall_loo <- cv.glm(data=landslides, fitSmall, K = nrow(landslides))
# Estimation error
cvSmall_loo$delta[1]

# Conducting k-fold cross validation for fitSmall, k = 10
cvSmall_kfold <- cv.glm(data=landslides, fitSmall, K = 10)
# Estimation error
cvSmall_kfold$delta[1]

# Comparing the performance of the two models
# Full model (fitFull)
cvFull_loo <- cv.glm(data=landslides, fitFull, K = nrow(landslides))
# Estimation error
cvFull_loo$delta[1]

cvFull_kfold <- cv.glm(data=landslides, fitFull, K = 10)
# Estimation error
cvFull_kfold$delta[1]


```
</div>

Like in multiple regression, prediction can be made for the un-sampled
locations based on the logistic regression model. For non-spatial cases,
the function `predict()` can be used for the prediction. For this lab, 
the explanatory variables are all raster images. The `raster` package provide a
convenient function `raster::predict()` to produce an estimation map based
on the raster layers. 

<div class="question">

**Q4:** Please read the help doc of `raster::predict()` and make a prediction
map of the study area (make sure you specify `type='response'` when using
this prediction function). Please map the prediction results and explain what the values of the prediction map
means. (20 pts)

**Your answer:**
 

```{r}
# Please type your codes here:
# load the landslides points
landslides <- readRDS("Data/landslides.rds")

# create binary response variable indicating presence or absence of landslides
landslides$lslpts <- ifelse(is.na(landslides$lsl), 0, 1)

# convert terrain object to RasterStack if not already
if (!is(terrain, "RasterStack")) {
  terrain <- stack(terrain)
}

# extract terrain attributes from terrain raster stack at landslide locations
slides <- SpatialPointsDataFrame(coordinates(landslides), data.frame(lslpts=as.numeric(landslides$lslpts)))
predictors <- raster::extract(terrain, slides, method="simple")

# combine response and predictor variables into a single data frame
data <- cbind(landslides["lslpts"], predictors)

# fit logistic regression model
model <- glm(lslpts ~ ., data=data, family=binomial)

# generate prediction map
if (!is(terrain, "RasterStack")) {
  terrain <- stack(terrain)
}
prediction <- raster::predict(terrain, model, type='response')

# convert prediction to data frame
pred_df <- as.data.frame(prediction)
names(pred_df) <- c("value")

# add x and y coordinates as columns
pred_df$x <- coordinates(terrain)[,1]
pred_df$y <- coordinates(terrain)[,2]

# plot the prediction map
ggplot(data=pred_df, aes(x=x, y=y, fill=value)) +
  geom_raster() +
  scale_fill_gradient(low='white', high='red') +
  theme_void() +
  theme(legend.position='bottom') +
  labs(title='Landslide Susceptibility Prediction Map')

```

**Q5:** Based on the prediction results, please map the areas with values
larger than 0.5 and overlay the map with the landsldies points
(differentiate the points with presences or not). Please comment on your
findings. (20 pts)


**Your answer: From the map, we can see that the areas with the highest predicted landslide susceptibility are concentrated in the western and southern parts of the study area, particularly in the hilly regions. The presence of landslides mostly overlaps with the areas of high predicted susceptibility, suggesting that the model has captured the underlying factors contributing to landslide occurrence in the study area. However, the model may still have limitations in terms of predicting the exact locations and timing of landslides, as these may be influenced by site-specific factors that are not fully captured by the available terrain attributes. Further refinement of the model and incorporation of additional data sources may be necessary to improve its accuracy and applicability.**


```{r}

# please type your codes here:
# identify cells with predicted probability > 0.5
pred_df_sub <- pred_df[pred_df$value > 0.5, ]

# plot the prediction map with landslides
ggplot() +
  geom_raster(data=pred_df, aes(x=x, y=y, fill=value)) +
  geom_point(data=landslides, aes(x=x, y=y, color=factor(lslpts)), size=1.5) +
  geom_point(data=pred_df_sub, aes(x=x, y=y), color="red", size=1.5) +
  scale_fill_gradient(low='white', high='red') +
  scale_color_manual(values=c("black", "red")) +
  theme_void() +
  theme(legend.position='bottom') +
  labs(title='Landslide Susceptibility Prediction Map')

```
</div>


<div class="question">

**Q6:** Please explain under what assumptions that logistic regression
works. Are these assumptions satisfied for this case of landslides
susceptibility mapping? What methods can be used to check if the
assumptions are satisfied? (10 pts)

**Your answer: For the case of landslides susceptibility mapping, logistic regression can be used assuming the above assumptions are satisfied. However, these assumptions need to be checked to ensure the validity of the model. Methods such as residual plots, the Hosmer-Lemeshow test, the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) can be used to check if the assumptions are satisfied. Residual plots can help to identify non-linearity or heteroscedasticity in the relationship between the dependent and independent variables. The Hosmer-Lemeshow test can be used to assess whether the predicted probabilities from the model are similar to the observed probabilities. The AIC and BIC are used to compare the goodness of fit between different models, with lower values indicating a better fit. Overall, it is important to check the assumptions of the logistic regression model to ensure the accuracy and reliability of the results.**


</div>
